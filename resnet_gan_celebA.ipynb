{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2544971328408771187,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8561947695760106714\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 7786181824176503511\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23228448768\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 11302149826802823852\n",
       " physical_device_desc: \"device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import glob,os\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow_datasets as tfds\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n",
      "WARNING:tensorflow:The operation `tf.image.convert_image_dtype` will be skipped since the input and output dtypes are identical.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/Downloads/celeba/'\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                    data_dir,\n",
    "                    label_mode = None,\n",
    "                    batch_size = 1,\n",
    "                    image_size = (64,64))\n",
    "train_ds = train_ds.unbatch()\n",
    "N_IMAGES = 100000\n",
    "train_ds = train_ds.take(N_IMAGES)\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 128\n",
    "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_ds = train_ds.map(lambda x: (x-127.5)/127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in train_ds.take(1):\n",
    "    plt.imshow(item[0,...]*0.5+0.5)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'images/resnet_celeb2/'\n",
    "for f in glob.glob(dir_name+'*.png'):\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetUpSampleBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filter_size,kernel_size):\n",
    "        super(ResnetUpSampleBlock, self).__init__(name='')\n",
    "        \n",
    "        self.conv2a = tf.keras.layers.Conv2DTranspose(filter_size, kernel_size=(3, 3), strides=(1,1), \n",
    "                                                      padding='same',use_bias=False)\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2b = tf.keras.layers.Conv2DTranspose(filter_size, kernel_size, strides=(2,2), \n",
    "                                                      padding='same',use_bias=False)\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2c = tf.keras.layers.Conv2DTranspose(filter_size, kernel_size=(3, 3),strides=(1,1), \n",
    "                                                      padding='same',use_bias=False)\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.convReshape = tf.keras.layers.Conv2DTranspose(filter_size,kernel_size=(1,1),strides=(2,2),\n",
    "                                                 padding='same',use_bias=False)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "    \n",
    "        input_tensor_reshaped = self.convReshape(input_tensor)\n",
    "        x += input_tensor_reshaped\n",
    "        return tf.nn.relu(x)\n",
    "    \n",
    "class ResnetDownSampleBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,filter_size, kernel_size):\n",
    "        super(ResnetDownSampleBlock, self).__init__(name='')\n",
    "\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filter_size, kernel_size=(3, 3), strides=(1,1),\n",
    "                                             padding='same',use_bias=False)\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2b = tf.keras.layers.Conv2D(filter_size, kernel_size, strides=(2,2), \n",
    "                                             padding='same',use_bias=False)\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2c = tf.keras.layers.Conv2D(filter_size, kernel_size=(3, 3),strides=(1,1), \n",
    "                                             padding='same',use_bias=False)\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.convReshape = tf.keras.layers.Conv2D(filter_size,kernel_size=(1,1),strides=(2,2),\n",
    "                                                 padding='same',use_bias=False)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "        \n",
    "        input_tensor_reshaped = self.convReshape(input_tensor)\n",
    "        x += input_tensor_reshaped\n",
    "        return tf.nn.leaky_relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(latent_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(latent_dim,)))\n",
    "    model.add(layers.Reshape((8, 8, 256)))\n",
    "    assert model.output_shape == (None, 8, 8, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(ResnetUpSampleBlock(256,3))\n",
    "    assert model.output_shape == (None,16,16,256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(ResnetUpSampleBlock(256,3))\n",
    "    assert model.output_shape == (None,32,32,256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(ResnetUpSampleBlock(256,3))\n",
    "    assert model.output_shape == (None,64,64,256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(3, (3, 3), strides=(1, 1), padding='same', \n",
    "                            use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 64 , 64, 3)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(ResnetDownSampleBlock(128,3))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(ResnetDownSampleBlock(128,3))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(ResnetDownSampleBlock(128,3))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "generator = make_generator(latent_dim)\n",
    "discriminator = make_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss():\n",
    "    z = tf.random.normal([BATCH_SIZE,latent_dim])\n",
    "    fake_images = generator(z,training=True)\n",
    "    fake_output = discriminator(fake_images,training=True)\n",
    "    g_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
    "    return g_loss\n",
    "\n",
    "def discriminator_loss(real_images):\n",
    "    z = tf.random.normal([BATCH_SIZE,latent_dim])\n",
    "    fake_images = generator(z,training=True)\n",
    "    fake_output = discriminator(fake_images,training=True)\n",
    "    real_output = discriminator(real_images,training=True)\n",
    "    d_loss_real = tf.reduce_mean(tf.math.log(real_output))\n",
    "    d_loss_fake = tf.reduce_mean(tf.math.log(1.0-fake_output))\n",
    "    d_loss = d_loss_real+d_loss_fake\n",
    "    return -d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generator_samples(epoch):\n",
    "    z = tf.random.normal([16,latent_dim])\n",
    "    images = generator(z,training=False)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(images[i]*0.5+0.5)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('epoch: %03d'%(epoch))\n",
    "    plt.savefig(dir_name+'image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D loss: 0.293 G loss: 2.664:   3%|â–Ž         | 3/100 [16:41<8:59:38, 333.80s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f5700d0a7e63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msave_generator_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f5700d0a7e63>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"D loss: %0.3f G loss: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LR = 1e-4\n",
    "BETA_1 = 0.5\n",
    "generator_opt = tf.keras.optimizers.Adam(learning_rate=LR,beta_1=BETA_1)\n",
    "discriminator_opt = tf.keras.optimizers.Adam(learning_rate=LR,beta_1=BETA_1)\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_images): \n",
    "    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "        g_loss = generator_loss()\n",
    "        d_loss = discriminator_loss(real_images)\n",
    "       \n",
    "    g_grad = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    d_grad = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    generator_opt.apply_gradients(zip(g_grad,generator.trainable_variables))\n",
    "    discriminator_opt.apply_gradients(zip(d_grad,discriminator.trainable_variables))\n",
    "    \n",
    "    return d_loss,g_loss\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    t = trange(epochs)\n",
    "    for epoch in t:\n",
    "        for data_batch in dataset:\n",
    "            d_loss,g_loss = train_step(data_batch)\n",
    "            t.set_description(\"D loss: %0.3f G loss: %0.3f\" %(d_loss.numpy(),g_loss.numpy()))\n",
    "            t.refresh()\n",
    "        save_generator_samples(epoch)\n",
    "EPOCHS = 100\n",
    "train(train_ds,EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "anim_file = 'resnet_gan_celeb2.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I',fps=1) as writer:\n",
    "    filenames = glob.glob(dir_name+'image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(model,size):\n",
    "    z = tf.random.normal([size**2,latent_dim])\n",
    "    images = model(z,training=False)\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    for i in range(size**2):\n",
    "        plt.subplot(size,size,i+1)\n",
    "        plt.imshow(images[i]*0.5+0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(generator,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#saving and loading model\n",
    "generator.compile(generator_opt)\n",
    "generator.save('models/resnet_celeb/generator')\n",
    "\n",
    "discriminator.compile(discriminator_opt)\n",
    "discriminator.save('models/resnet_celeb/disciminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_new = tf.keras.models.load_model('models/resnet_celeb/generator')\n",
    "plot_samples(generator_new,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
